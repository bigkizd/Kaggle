{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Digit Recognizer",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Kaggle/blob/master/Digit%20Recognizer/Digit_Recognizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "oWVAcIYxSCqj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "f8413d11-0a1b-4e4e-977b-d312b704b67a"
      },
      "cell_type": "code",
      "source": [
        "#Import Library\n",
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.examples.tutorials.mnist import input_data\n",
        "# mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=False)\n",
        "import tensorflow as tf\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Dqo02l1KSWDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path_train = '/content/drive/My Drive/Datasets/Digit Recognizer/train.csv'\n",
        "path_test = '/content/drive/My Drive/Datasets/Digit Recognizer/test.csv'\n",
        "#Read Data\n",
        "train = pd.read_csv(path_train)\n",
        "test = pd.read_csv(path_test)\n",
        "# Convert to numpy\n",
        "train = np.asarray(train, np.float32)\n",
        "test = np.asarray(test, np.float32)\n",
        "\n",
        "X_train = train[:, 1:]\n",
        "y_train = np.reshape(train[:, :1], (train.shape[0], ))\n",
        "del train\n",
        "del path_train\n",
        "del path_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2ux1ysvWSjzZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Training Parameters\n",
        "learning_rate = 0.001\n",
        "num_steps = 3000\n",
        "batch_size = 128\n",
        "\n",
        "# Network Parameters\n",
        "num_input = 784 # MNIST data input (img shape: 28*28)\n",
        "num_classes = 10 # MNIST total classes (0-9 digits)\n",
        "dropout = 0.25 # Dropout, probability to drop a unit\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cymJr27XS0jD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Create Model\n",
        "# Any results you write to the current directory are saved as output.\n",
        "def conv_net(X, n_classes, dropout, reuse, is_training):\n",
        "    with tf.variable_scope('Convnet', reuse=reuse):\n",
        "        x=X['images']\n",
        "        x=tf.reshape(x, shape=[-1, 28, 28, 1])\n",
        "        conv1 = tf.layers.conv2d(x, 32, 5, activation=tf.nn.relu)\n",
        "        \n",
        "        conv1 = tf.layers.max_pooling2d(conv1, 2, 2)\n",
        "        conv2 = tf.layers.conv2d(conv1, 64, 3, activation=tf.nn.relu)\n",
        "        conv2 = tf.layers.max_pooling2d(conv2, 2, 2)\n",
        "        fc1 = tf.contrib.layers.flatten(conv2)\n",
        "        fc1 = tf.layers.dense(fc1, 1024)\n",
        "        fc1 = tf.layers.dropout(fc1, rate=dropout, training=is_training)\n",
        "        out = tf.layers.dense(fc1, n_classes)\n",
        "        \n",
        "    return out\n",
        "def model_fn(features, labels, mode):\n",
        "    logits_train = conv_net(features, num_classes, dropout, reuse=False, is_training=True)\n",
        "    logits_test = conv_net(features, num_classes, dropout, reuse=True, is_training=False)\n",
        "    prediction = {\n",
        "      \"classes\": tf.argmax(input=logits_test, axis=1),\n",
        "      \"probabilities\": tf.nn.softmax(logits_test, name=\"softmax_tensor\")\n",
        "    }\n",
        "    if(mode==tf.estimator.ModeKeys.PREDICT):\n",
        "        return tf.estimator.EstimatorSpec(mode, predictions=prediction)\n",
        "    loss_op = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
        "        logits=logits_train, labels=tf.cast(labels, dtype=tf.int32)))\n",
        "    optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "    train_op = optimizer.minimize(loss_op, global_step=tf.train.get_global_step())\n",
        "    acc_op = tf.metrics.accuracy(labels=labels, predictions=prediction['classes'])\n",
        "    estim_specs = tf.estimator.EstimatorSpec(\n",
        "        mode=mode,\n",
        "        predictions=prediction,\n",
        "        loss=loss_op,\n",
        "        train_op=train_op,\n",
        "        eval_metric_ops={'accuracy': acc_op})\n",
        "    return estim_specs\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BQUr4dbMS9Xu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1516
        },
        "outputId": "a10d5703-7ba4-4bcc-96c4-68a231e128e5"
      },
      "cell_type": "code",
      "source": [
        "model = tf.estimator.Estimator(model_fn)\n",
        "\n",
        "input_fn_train = tf.estimator.inputs.numpy_input_fn(x={'images': X_train}, y=y_train, batch_size=batch_size, num_epochs=None, shuffle=True)\n",
        "\n",
        "# Training Model\n",
        "model.train(input_fn_train, steps=num_steps)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpsos5vsn8\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpsos5vsn8', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f2a76df0d30>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_queue_runner.py:62: QueueRunner.__init__ (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/estimator/inputs/queues/feeding_functions.py:500: add_queue_runner (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/monitored_session.py:804: start_queue_runners (from tensorflow.python.training.queue_runner_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "To construct input pipelines, use the `tf.data` module.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmpsos5vsn8/model.ckpt.\n",
            "INFO:tensorflow:loss = 56.951805, step = 0\n",
            "INFO:tensorflow:global_step/sec: 107.982\n",
            "INFO:tensorflow:loss = 0.26748735, step = 100 (0.932 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.81\n",
            "INFO:tensorflow:loss = 0.17950769, step = 200 (0.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.283\n",
            "INFO:tensorflow:loss = 0.17668524, step = 300 (0.767 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.219\n",
            "INFO:tensorflow:loss = 0.033839256, step = 400 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.799\n",
            "INFO:tensorflow:loss = 0.05795689, step = 500 (0.777 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.635\n",
            "INFO:tensorflow:loss = 0.0185394, step = 600 (0.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.579\n",
            "INFO:tensorflow:loss = 0.18668118, step = 700 (0.772 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.263\n",
            "INFO:tensorflow:loss = 0.08546189, step = 800 (0.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.949\n",
            "INFO:tensorflow:loss = 0.13340762, step = 900 (0.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.508\n",
            "INFO:tensorflow:loss = 0.17344666, step = 1000 (0.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.037\n",
            "INFO:tensorflow:loss = 0.040282495, step = 1100 (0.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.074\n",
            "INFO:tensorflow:loss = 0.25104833, step = 1200 (0.749 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.103\n",
            "INFO:tensorflow:loss = 0.06240227, step = 1300 (0.758 sec)\n",
            "INFO:tensorflow:global_step/sec: 132.33\n",
            "INFO:tensorflow:loss = 0.07054439, step = 1400 (0.755 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.691\n",
            "INFO:tensorflow:loss = 0.109759845, step = 1500 (0.757 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.182\n",
            "INFO:tensorflow:loss = 0.07239305, step = 1600 (0.762 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.891\n",
            "INFO:tensorflow:loss = 0.13770995, step = 1700 (0.764 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.37\n",
            "INFO:tensorflow:loss = 0.019021867, step = 1800 (0.770 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.633\n",
            "INFO:tensorflow:loss = 0.013473931, step = 1900 (0.765 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.201\n",
            "INFO:tensorflow:loss = 0.07549432, step = 2000 (0.774 sec)\n",
            "INFO:tensorflow:global_step/sec: 129.687\n",
            "INFO:tensorflow:loss = 0.027814135, step = 2100 (0.773 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.196\n",
            "INFO:tensorflow:loss = 0.034804795, step = 2200 (0.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.03\n",
            "INFO:tensorflow:loss = 0.04085933, step = 2300 (0.771 sec)\n",
            "INFO:tensorflow:global_step/sec: 133.137\n",
            "INFO:tensorflow:loss = 0.047034733, step = 2400 (0.750 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.137\n",
            "INFO:tensorflow:loss = 0.05177459, step = 2500 (0.766 sec)\n",
            "INFO:tensorflow:global_step/sec: 130.116\n",
            "INFO:tensorflow:loss = 0.08948007, step = 2600 (0.769 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.068\n",
            "INFO:tensorflow:loss = 0.025905568, step = 2700 (0.763 sec)\n",
            "INFO:tensorflow:global_step/sec: 131.768\n",
            "INFO:tensorflow:loss = 0.06683625, step = 2800 (0.760 sec)\n",
            "INFO:tensorflow:global_step/sec: 128.801\n",
            "INFO:tensorflow:loss = 0.06434671, step = 2900 (0.774 sec)\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into /tmp/tmpsos5vsn8/model.ckpt.\n",
            "INFO:tensorflow:Loss for final step: 0.02071504.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.estimator.estimator.Estimator at 0x7f2a76df0be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "metadata": {
        "id": "txDMXupdfqFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "dd818a63-c0ef-4171-f535-45c721dfaa9e"
      },
      "cell_type": "code",
      "source": [
        "# Test model \n",
        "input_fn_test = tf.estimator.inputs.numpy_input_fn(\n",
        "    x={\"images\": test},\n",
        "    num_epochs=1,\n",
        "    shuffle=False)\n",
        "predictions = model.predict(input_fn=input_fn_test)\n",
        "cls = [p['classes'] for p in predictions]\n",
        "cls_pred = np.array(cls, dtype='int').squeeze()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmpsos5vsn8/model.ckpt-3000\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DFmbqmSOuG5u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert to csv to submit to Kaggle Competitive\n",
        "submit = pd.DataFrame()\n",
        "submit['ImageId'] = range(1, test.shape[0]+1)\n",
        "submit['Label'] = cls_pred\n",
        "submit.to_csv(\"submit.csv\", index=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3RDLU5cDxukP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2AGaVNb8QyQ7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}