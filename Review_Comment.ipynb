{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review_Comment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Kaggle/blob/master/Review_Comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KhbUtnMh7PL-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7285411f-1722-402a-f5e6-dab650fda302"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import pickle\n",
        "\n",
        "\n",
        "def readTxt(filename):\n",
        "  print(filename)\n",
        "  lines = []\n",
        "  with open(filename,encoding='utf-8', errors='ignore') as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  return lines\n",
        "\n",
        "neg = readTxt('neg_comment.txt')\n",
        "pos = readTxt('pos_comment.txt')\n",
        "\n",
        "y_neg = np.ones((len(neg), 1))\n",
        "y_pos = np.zeros((len(pos), 1))\n",
        "y_train = np.concatenate((y_neg, y_pos), axis=0)\n",
        "\n",
        "neg.extend(pos)\n",
        "all_text = neg\n",
        "del neg\n",
        "del pos\n",
        "del y_neg\n",
        "del y_pos\n",
        "def Fit_Pre(all_text):\n",
        "  word_vectorizer = TfidfVectorizer(\n",
        "      sublinear_tf=True,\n",
        "      strip_accents='unicode',\n",
        "      encoding='utf-8',\n",
        "      analyzer='word',\n",
        "      token_pattern=r'\\w{1,}',\n",
        "      stop_words='english',\n",
        "      ngram_range=(1, 1),\n",
        "      norm='l2',\n",
        "      min_df=0,\n",
        "      smooth_idf=False,\n",
        "      max_features=5000)\n",
        "  word_vectorizer.fit(all_text)\n",
        "  pickle.dump(word_vectorizer, open('word.sav', 'wb'))\n",
        "  #train_word_features = word_vectorizer.transform(train)\n",
        "  char_vectorizer = TfidfVectorizer(\n",
        "      sublinear_tf=True,\n",
        "      strip_accents='unicode',\n",
        "      analyzer='char',\n",
        "      stop_words='english',\n",
        "      ngram_range=(2, 6),\n",
        "      norm='l2',\n",
        "      min_df=0,\n",
        "      smooth_idf=False,\n",
        "      max_features=1500)\n",
        "  char_vectorizer.fit(all_text)\n",
        "  pickle.dump(char_vectorizer, open('char.sav', 'wb'))\n",
        "  #train_char_features = char_vectorizer.transform(train)\n",
        "  #train_features = hstack([train_char_features, train_word_features])\n",
        "  #return train_features\n",
        "Fit_Pre(all_text)\n",
        "def preprocessing(data):\n",
        "  word = pickle.load(open('word.sav', 'rb'))\n",
        "  char = pickle.load(open('char.sav', 'rb'))\n",
        "  word_features = word_vectorizer.transform(data)\n",
        "  char_features = char_vectorizer.transform(data)\n",
        "  features = hstack([char_features, word_features])\n",
        "  return features\n",
        "train_features = preprocessing(all_text)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neg_comment.txt\n",
            "pos_comment.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tu9J3S1R9af1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = train_features\n",
        "\n",
        "y = y_train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxBHB-UBCpBl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "185cdb82-4b43-469c-e27a-b6d100a63b64"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def LogReg(X_train, y_train):\n",
        "  log = LogisticRegression(C=13.0)\n",
        "  log.fit(X_train, y_train)\n",
        "  return log\n",
        "\n",
        "t = time.time()\n",
        "print(\"Fitting...\")\n",
        "model_logreg = LogReg(X_train, y_train)\n",
        "print(\"Done!\")\n",
        "print(\"Time to train with LogisticRegression: \", time.time()-t)\n"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Time to train with LogisticRegression:  0.8797769546508789\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MYPJD_d0GAUC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2c9f081b-cbb7-435b-f495-d44e4695b2d2"
      },
      "cell_type": "code",
      "source": [
        "pred_train_logreg = model_logreg.predict(X_train)\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, pred_train_logreg)))\n",
        "\n",
        "pred_test_logreg = model_logreg.predict(X_val)\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_val, pred_test_logreg)))\n"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9987109249113761\n",
            "Testing accuracy is 0.9800193361263294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRUZDIczGJDK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c88945aa-177a-4554-ce27-0b6772512560"
      },
      "cell_type": "code",
      "source": [
        "data = list()\n",
        "data.append('I guess I should have realized a smaller screen wouldn’t fit our needs so it’s reslly not a fault of Amazon.')\n",
        "data_test = preprocessing(data)\n",
        "\n",
        "print(model_logreg.predict(data_test))"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sp08Dn3BHF3l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7e9235e3-c439-46f7-ebfb-ae81f671ee9a"
      },
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I guess I should have realized a smaller screen wouldn’t fit our needs so it’s reslly not a fault of Amazon.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jAUZwP_AHnS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}