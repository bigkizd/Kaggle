{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Review_Comment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Kaggle/blob/master/Review_Comment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "KhbUtnMh7PL-",
        "colab_type": "code",
        "outputId": "f73585eb-9524-4d52-c02f-128fb93503b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from scipy.sparse import hstack\n",
        "import pickle\n",
        "\n",
        "\n",
        "def readTxt(filename):\n",
        "  print(filename)\n",
        "  lines = []\n",
        "  with open(filename,encoding='utf-8', errors='ignore') as f:\n",
        "    lines = f.readlines()\n",
        "  \n",
        "  return lines\n",
        "\n",
        "neg = readTxt('neg_comment.txt')\n",
        "pos = readTxt('pos_comment.txt')\n",
        "\n",
        "y_neg = np.ones((len(neg), 1))\n",
        "y_pos = np.zeros((len(pos), 1))\n",
        "y_train = np.concatenate((y_neg, y_pos), axis=0)\n",
        "\n",
        "neg.extend(pos)\n",
        "all_text = neg\n",
        "del neg\n",
        "del pos\n",
        "del y_neg\n",
        "del y_pos\n",
        "def Fit_Pre(all_text):\n",
        "  word_vectorizer = TfidfVectorizer(\n",
        "      sublinear_tf=True,\n",
        "      strip_accents='unicode',\n",
        "      encoding='utf-8',\n",
        "      analyzer='word',\n",
        "      token_pattern=r'\\w{1,}',\n",
        "      stop_words='english',\n",
        "      ngram_range=(1, 1),\n",
        "      norm='l2',\n",
        "      min_df=0,\n",
        "      smooth_idf=False,\n",
        "      max_features=5000)\n",
        "  word_vectorizer.fit(all_text)\n",
        "  pickle.dump(word_vectorizer, open('word.sav', 'wb'))\n",
        "  #train_word_features = word_vectorizer.transform(train)\n",
        "  char_vectorizer = TfidfVectorizer(\n",
        "      sublinear_tf=True,\n",
        "      strip_accents='unicode',\n",
        "      analyzer='char',\n",
        "      stop_words='english',\n",
        "      ngram_range=(2, 6),\n",
        "      norm='l2',\n",
        "      min_df=0,\n",
        "      smooth_idf=False,\n",
        "      max_features=1500)\n",
        "  char_vectorizer.fit(all_text)\n",
        "  pickle.dump(char_vectorizer, open('char.sav', 'wb'))\n",
        "  #train_char_features = char_vectorizer.transform(train)\n",
        "  #train_features = hstack([train_char_features, train_word_features])\n",
        "  #return train_features\n",
        "Fit_Pre(all_text)\n",
        "def preprocessing(data):\n",
        "  word = pickle.load(open('word.sav', 'rb'))\n",
        "  char = pickle.load(open('char.sav', 'rb'))\n",
        "  word_features = word.transform(data)\n",
        "  char_features = char.transform(data)\n",
        "  features = hstack([char_features, word_features])\n",
        "  return features\n",
        "train_features = preprocessing(all_text)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "neg_comment.txt\n",
            "pos_comment.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "tu9J3S1R9af1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = train_features\n",
        "\n",
        "y = y_train\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FxBHB-UBCpBl",
        "colab_type": "code",
        "outputId": "8f8aae46-1f29-4773-e830-332c41ee7895",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "\n",
        "def LogReg(X_train, y_train):\n",
        "  log = LogisticRegression(C=13.0)\n",
        "  log.fit(X_train, y_train)\n",
        "  return log\n",
        "\n",
        "t = time.time()\n",
        "print(\"Fitting...\")\n",
        "model_logreg = LogReg(X_train, y_train)\n",
        "print(\"Done!\")\n",
        "print(\"Time to train with LogisticRegression: \", time.time()-t)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Time to train with LogisticRegression:  0.6392419338226318\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MYPJD_d0GAUC",
        "colab_type": "code",
        "outputId": "2da51aee-87b9-4e28-b9db-53d271c1d9b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "pred_train_logreg = model_logreg.predict(X_train)\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, pred_train_logreg)))\n",
        "\n",
        "pred_test_logreg = model_logreg.predict(X_val)\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_val, pred_test_logreg)))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training accuracy is 0.9987109249113761\n",
            "Testing accuracy is 0.9800193361263294\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "oRUZDIczGJDK",
        "colab_type": "code",
        "outputId": "d0e24070-2b5c-4183-965a-175ec6a38a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = list()\n",
        "data.append('I guess I should have realized a smaller screen wouldn’t fit our needs so it’s reslly not a fault of Amazon.')\n",
        "data_test = preprocessing(data)\n",
        "\n",
        "print(model_logreg.predict(data_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5em2UwZaOhRI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Support Vector Machine"
      ]
    },
    {
      "metadata": {
        "id": "07TpQjB3OeoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "5c9f608e-f8ed-4bea-dafc-cce083d1d9fc"
      },
      "cell_type": "code",
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "svm = SVC(C=13.0)\n",
        "svm.fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
            "  \"avoid this warning.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "voda0ty9PMRS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "print('Training accuracy is {}'.format(accuracy_score(y_train, svm.predict(X_train))))\n",
        "\n",
        "print('Testing accuracy is {}'.format(accuracy_score(y_val, svm.predict(X_val))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0pM1ipOgOe-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Sp08Dn3BHF3l",
        "colab_type": "code",
        "outputId": "f1b98fc4-726f-449f-ad6b-b00efd5efdb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['I guess I should have realized a smaller screen wouldn’t fit our needs so it’s reslly not a fault of Amazon.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jAUZwP_AHnS6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}