{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TGS Salt Identification Challenge.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Kaggle/blob/master/TGS_Salt_Identification_Challenge/TGS_Salt_Identification_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "-n6rnRT-jlva",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n4OsIvOOiaQB",
        "colab_type": "code",
        "outputId": "4b502daf-cb31-4c35-8e81-0e09cf70dcd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-white')\n",
        "import seaborn as sns\n",
        "sns.set_style(\"white\")\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "# import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from tqdm import trange #, tnrange\n",
        "#from itertools import chain\n",
        "from skimage.io import imread, imshow #, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model, save_model\n",
        "from keras.layers import Input,Dropout,BatchNormalization,Activation,Add\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras import backend as K\n",
        "from keras import optimizers\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img#,save_img\n",
        "\n",
        "import time\n",
        "t_start = time.time()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "wDTdCo0Pjumq",
        "colab_type": "code",
        "outputId": "eef66b05-45a5-47a3-bb81-e1a513af763d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "version = 5\n",
        "basic_name = f'Unet_resnet_v{version}'\n",
        "save_model_name = basic_name + '.model'\n",
        "submission_file = basic_name + '.csv'\n",
        "\n",
        "print(save_model_name)\n",
        "print(submission_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Unet_resnet_v5.model\n",
            "Unet_resnet_v5.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jwGXN18XjyQp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "img_size_ori = 101\n",
        "img_size_target = 101\n",
        "\n",
        "def upsample(img):# not used\n",
        "    if img_size_ori == img_size_target:\n",
        "        return img\n",
        "    return resize(img, (img_size_target, img_size_target), mode='constant', preserve_range=True)\n",
        "    \n",
        "def downsample(img):# not used\n",
        "    if img_size_ori == img_size_target:\n",
        "        return img\n",
        "    return resize(img, (img_size_ori, img_size_ori), mode='constant', preserve_range=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RXjZzVooj6kg",
        "colab_type": "code",
        "outputId": "7296ef62-e7a4-4814-e0e7-abf67526d87c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ahFZWTRBj3kX",
        "colab_type": "code",
        "outputId": "407c632b-9172-4b2d-e115-2d220edd7b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "data_dir= 'drive/My Drive/Dataset/TGS Salt Identification Challenge/'\n",
        "# Loading of training/testing ids and depths\n",
        "train_df = pd.read_csv(data_dir+\"train.csv\", index_col=\"id\", usecols=[0])\n",
        "depths_df = pd.read_csv(data_dir+\"depths.csv\", index_col=\"id\")\n",
        "train_df = train_df.join(depths_df)\n",
        "test_df = depths_df[~depths_df.index.isin(train_df.index)]\n",
        "\n",
        "len(train_df)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "metadata": {
        "id": "vt5h5xFj9TIx",
        "colab_type": "code",
        "outputId": "e6438063-312d-48aa-da0e-d6b97ac81715",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.28.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "q-oteZqfkGMK",
        "colab_type": "code",
        "outputId": "474f377b-4222-4b07-f7bc-e56c476814f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_df[\"images\"] = [np.array(load_img(data_dir+\"train/images/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [18:46<00:00,  3.51it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rIVwte5Cj3np",
        "colab_type": "code",
        "outputId": "ca53c614-765a-49ac-e756-0e6415785f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "train_df[\"masks\"] = [np.array(load_img(data_dir+\"train/masks/{}.png\".format(idx), grayscale=True)) / 255 for idx in tqdm(train_df.index)]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 4000/4000 [22:07<00:00,  3.49it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "CnJ2XDKGj3qh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_df[\"coverage\"] = train_df.masks.map(np.sum) / pow(img_size_ori, 2)\n",
        "\n",
        "def cov_to_class(val):    \n",
        "    for i in range(0, 11):\n",
        "        if val * 10 <= i :\n",
        "            return i\n",
        "        \n",
        "train_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YNSUXBLMj3tw",
        "colab_type": "code",
        "outputId": "17d5351d-89c8-4910-a9fd-a639bf5e7f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "cell_type": "code",
      "source": [
        "fig, axs = plt.subplots(1, 2, figsize=(15,5))\n",
        "sns.distplot(train_df.coverage, kde=False, ax=axs[0])\n",
        "sns.distplot(train_df.coverage_class, bins=10, kde=False, ax=axs[1])\n",
        "plt.suptitle(\"Salt coverage\")\n",
        "axs[0].set_xlabel(\"Coverage\")\n",
        "axs[1].set_xlabel(\"Coverage class\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,0,'Coverage class')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAFhCAYAAAAx/0jAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSZIkdYQBTpIkSZI64v8DtQ94eEvx5aEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0557d02198>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "FySukg5fkRXA",
        "colab_type": "code",
        "outputId": "03e438b7-ae65-4171-a642-b9547c9b298b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 311
        }
      },
      "cell_type": "code",
      "source": [
        "sns.distplot(train_df.z, label=\"Train\")\n",
        "sns.distplot(test_df.z, label=\"Test\")\n",
        "plt.legend()\n",
        "plt.title(\"Depth distribution\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5,1,'Depth distribution')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEVCAYAAAD6u3K7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEMYYY+KyBGGMMSYuSxDGGGPi+n+goTLbMRNRlQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f0557d95320>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "nXNIMReikRZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "ids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n",
        "    train_df.index.values,\n",
        "    np.array(train_df.images.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
        "    np.array(train_df.masks.map(upsample).tolist()).reshape(-1, img_size_target, img_size_target, 1), \n",
        "    train_df.coverage.values,\n",
        "    train_df.z.values,\n",
        "    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ChW4M_dykRce",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def BatchActivate(x):\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def convolution_block(x, filters, size, strides=(1,1), padding='same', activation=True):\n",
        "    x = Conv2D(filters, size, strides=strides, padding=padding)(x)\n",
        "    if activation == True:\n",
        "        x = BatchActivate(x)\n",
        "    return x\n",
        "\n",
        "def residual_block(blockInput, num_filters=16, batch_activate = False):\n",
        "    x = BatchActivate(blockInput)\n",
        "    x = convolution_block(x, num_filters, (3,3) )\n",
        "    x = convolution_block(x, num_filters, (3,3), activation=False)\n",
        "    x = Add()([x, blockInput])\n",
        "    if batch_activate:\n",
        "        x = BatchActivate(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZvTEXaV6kRf3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Build model\n",
        "def build_model(input_layer, start_neurons, DropoutRatio = 0.5):\n",
        "    # 101 -> 50\n",
        "    conv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(input_layer)\n",
        "    conv1 = residual_block(conv1,start_neurons * 1)\n",
        "    conv1 = residual_block(conv1,start_neurons * 1, True)\n",
        "    pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "    pool1 = Dropout(DropoutRatio/2)(pool1)\n",
        "\n",
        "    # 50 -> 25\n",
        "    conv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(pool1)\n",
        "    conv2 = residual_block(conv2,start_neurons * 2)\n",
        "    conv2 = residual_block(conv2,start_neurons * 2, True)\n",
        "    pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "    pool2 = Dropout(DropoutRatio)(pool2)\n",
        "\n",
        "    # 25 -> 12\n",
        "    conv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(pool2)\n",
        "    conv3 = residual_block(conv3,start_neurons * 4)\n",
        "    conv3 = residual_block(conv3,start_neurons * 4, True)\n",
        "    pool3 = MaxPooling2D((2, 2))(conv3)\n",
        "    pool3 = Dropout(DropoutRatio)(pool3)\n",
        "\n",
        "    # 12 -> 6\n",
        "    conv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(pool3)\n",
        "    conv4 = residual_block(conv4,start_neurons * 8)\n",
        "    conv4 = residual_block(conv4,start_neurons * 8, True)\n",
        "    pool4 = MaxPooling2D((2, 2))(conv4)\n",
        "    pool4 = Dropout(DropoutRatio)(pool4)\n",
        "\n",
        "    # Middle\n",
        "    convm = Conv2D(start_neurons * 16, (3, 3), activation=None, padding=\"same\")(pool4)\n",
        "    convm = residual_block(convm,start_neurons * 16)\n",
        "    convm = residual_block(convm,start_neurons * 16, True)\n",
        "    \n",
        "    # 6 -> 12\n",
        "    deconv4 = Conv2DTranspose(start_neurons * 8, (3, 3), strides=(2, 2), padding=\"same\")(convm)\n",
        "    uconv4 = concatenate([deconv4, conv4])\n",
        "    uconv4 = Dropout(DropoutRatio)(uconv4)\n",
        "    \n",
        "    uconv4 = Conv2D(start_neurons * 8, (3, 3), activation=None, padding=\"same\")(uconv4)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8)\n",
        "    uconv4 = residual_block(uconv4,start_neurons * 8, True)\n",
        "    \n",
        "    # 12 -> 25\n",
        "    #deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"same\")(uconv4)\n",
        "    deconv3 = Conv2DTranspose(start_neurons * 4, (3, 3), strides=(2, 2), padding=\"valid\")(uconv4)\n",
        "    uconv3 = concatenate([deconv3, conv3])    \n",
        "    uconv3 = Dropout(DropoutRatio)(uconv3)\n",
        "    \n",
        "    uconv3 = Conv2D(start_neurons * 4, (3, 3), activation=None, padding=\"same\")(uconv3)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4)\n",
        "    uconv3 = residual_block(uconv3,start_neurons * 4, True)\n",
        "\n",
        "    # 25 -> 50\n",
        "    deconv2 = Conv2DTranspose(start_neurons * 2, (3, 3), strides=(2, 2), padding=\"same\")(uconv3)\n",
        "    uconv2 = concatenate([deconv2, conv2])\n",
        "        \n",
        "    uconv2 = Dropout(DropoutRatio)(uconv2)\n",
        "    uconv2 = Conv2D(start_neurons * 2, (3, 3), activation=None, padding=\"same\")(uconv2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2)\n",
        "    uconv2 = residual_block(uconv2,start_neurons * 2, True)\n",
        "    \n",
        "    # 50 -> 101\n",
        "    #deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"same\")(uconv2)\n",
        "    deconv1 = Conv2DTranspose(start_neurons * 1, (3, 3), strides=(2, 2), padding=\"valid\")(uconv2)\n",
        "    uconv1 = concatenate([deconv1, conv1])\n",
        "    \n",
        "    uconv1 = Dropout(DropoutRatio)(uconv1)\n",
        "    uconv1 = Conv2D(start_neurons * 1, (3, 3), activation=None, padding=\"same\")(uconv1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1)\n",
        "    uconv1 = residual_block(uconv1,start_neurons * 1, True)\n",
        "    \n",
        "    #uconv1 = Dropout(DropoutRatio/2)(uconv1)\n",
        "    #output_layer = Conv2D(1, (1,1), padding=\"same\", activation=\"sigmoid\")(uconv1)\n",
        "    output_layer_noActi = Conv2D(1, (1,1), padding=\"same\", activation=None)(uconv1)\n",
        "    output_layer =  Activation('sigmoid')(output_layer_noActi)\n",
        "    \n",
        "    return output_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pdMsvIxAIITw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_iou_vector(A, B):\n",
        "    batch_size = A.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        t, p = A[batch]>0, B[batch]>0\n",
        "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) > 0:\n",
        "#             metric.append(0)\n",
        "#             continue\n",
        "#         if np.count_nonzero(t) >= 1 and np.count_nonzero(p) == 0:\n",
        "#             metric.append(0)\n",
        "#             continue\n",
        "#         if np.count_nonzero(t) == 0 and np.count_nonzero(p) == 0:\n",
        "#             metric.append(1)\n",
        "#             continue\n",
        "        \n",
        "        intersection = np.logical_and(t, p)\n",
        "        union = np.logical_or(t, p)\n",
        "        iou = (np.sum(intersection > 0) + 1e-10 )/ (np.sum(union > 0) + 1e-10)\n",
        "        thresholds = np.arange(0.5, 1, 0.05)\n",
        "        s = []\n",
        "        for thresh in thresholds:\n",
        "            s.append(iou > thresh)\n",
        "        metric.append(np.mean(s))\n",
        "\n",
        "    return np.mean(metric)\n",
        "\n",
        "def my_iou_metric(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred>0.5], tf.float64)\n",
        "\n",
        "def my_iou_metric_2(label, pred):\n",
        "    return tf.py_func(get_iou_vector, [label, pred >0], tf.float64)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ISjIf2HwIKq5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# code download from: https://github.com/bermanmaxim/LovaszSoftmax\n",
        "def lovasz_grad(gt_sorted):\n",
        "    \"\"\"\n",
        "    Computes gradient of the Lovasz extension w.r.t sorted errors\n",
        "    See Alg. 1 in paper\n",
        "    \"\"\"\n",
        "    gts = tf.reduce_sum(gt_sorted)\n",
        "    intersection = gts - tf.cumsum(gt_sorted)\n",
        "    union = gts + tf.cumsum(1. - gt_sorted)\n",
        "    jaccard = 1. - intersection / union\n",
        "    jaccard = tf.concat((jaccard[0:1], jaccard[1:] - jaccard[:-1]), 0)\n",
        "    return jaccard\n",
        "\n",
        "\n",
        "# --------------------------- BINARY LOSSES ---------------------------\n",
        "\n",
        "def lovasz_hinge(logits, labels, per_image=True, ignore=None):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n",
        "      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n",
        "      per_image: compute the loss per image instead of per batch\n",
        "      ignore: void class id\n",
        "    \"\"\"\n",
        "    if per_image:\n",
        "        def treat_image(log_lab):\n",
        "            log, lab = log_lab\n",
        "            log, lab = tf.expand_dims(log, 0), tf.expand_dims(lab, 0)\n",
        "            log, lab = flatten_binary_scores(log, lab, ignore)\n",
        "            return lovasz_hinge_flat(log, lab)\n",
        "        losses = tf.map_fn(treat_image, (logits, labels), dtype=tf.float32)\n",
        "        loss = tf.reduce_mean(losses)\n",
        "    else:\n",
        "        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n",
        "    return loss\n",
        "\n",
        "\n",
        "def lovasz_hinge_flat(logits, labels):\n",
        "    \"\"\"\n",
        "    Binary Lovasz hinge loss\n",
        "      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n",
        "      labels: [P] Tensor, binary ground truth labels (0 or 1)\n",
        "      ignore: label to ignore\n",
        "    \"\"\"\n",
        "\n",
        "    def compute_loss():\n",
        "        labelsf = tf.cast(labels, logits.dtype)\n",
        "        signs = 2. * labelsf - 1.\n",
        "        errors = 1. - logits * tf.stop_gradient(signs)\n",
        "        errors_sorted, perm = tf.nn.top_k(errors, k=tf.shape(errors)[0], name=\"descending_sort\")\n",
        "        gt_sorted = tf.gather(labelsf, perm)\n",
        "        grad = lovasz_grad(gt_sorted)\n",
        "        loss = tf.tensordot(tf.nn.relu(errors_sorted), tf.stop_gradient(grad), 1, name=\"loss_non_void\")\n",
        "        return loss\n",
        "\n",
        "    # deal with the void prediction case (only void pixels)\n",
        "    loss = tf.cond(tf.equal(tf.shape(logits)[0], 0),\n",
        "                   lambda: tf.reduce_sum(logits) * 0.,\n",
        "                   compute_loss,\n",
        "                   strict=True,\n",
        "                   name=\"loss\"\n",
        "                   )\n",
        "    return loss\n",
        "\n",
        "\n",
        "def flatten_binary_scores(scores, labels, ignore=None):\n",
        "    \"\"\"\n",
        "    Flattens predictions in the batch (binary case)\n",
        "    Remove labels equal to 'ignore'\n",
        "    \"\"\"\n",
        "    scores = tf.reshape(scores, (-1,))\n",
        "    labels = tf.reshape(labels, (-1,))\n",
        "    if ignore is None:\n",
        "        return scores, labels\n",
        "    valid = tf.not_equal(labels, ignore)\n",
        "    vscores = tf.boolean_mask(scores, valid, name='valid_scores')\n",
        "    vlabels = tf.boolean_mask(labels, valid, name='valid_labels')\n",
        "    return vscores, vlabels\n",
        "\n",
        "def lovasz_loss(y_true, y_pred):\n",
        "    y_true, y_pred = K.cast(K.squeeze(y_true, -1), 'int32'), K.cast(K.squeeze(y_pred, -1), 'float32')\n",
        "    #logits = K.log(y_pred / (1. - y_pred))\n",
        "    logits = y_pred #Jiaxin\n",
        "    loss = lovasz_hinge(logits, y_true, per_image = True, ignore = None)\n",
        "    return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hW31A4QiIQ7q",
        "colab_type": "code",
        "outputId": "6d915233-1280-44c2-9385-4aabe8c33452",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "#Data augmentation\n",
        "x_train = np.append(x_train, [np.fliplr(x) for x in x_train], axis=0)\n",
        "y_train = np.append(y_train, [np.fliplr(x) for x in y_train], axis=0)\n",
        "print(x_train.shape)\n",
        "print(y_valid.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6400, 101, 101, 1)\n",
            "(800, 101, 101, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pXiEbDRAITUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# model\n",
        "input_layer = Input((img_size_target, img_size_target, 1))\n",
        "output_layer = build_model(input_layer, 16,0.5)\n",
        "\n",
        "model1 = Model(input_layer, output_layer)\n",
        "\n",
        "c = optimizers.adam(lr = 0.01)\n",
        "model1.compile(loss=\"binary_crossentropy\", optimizer=c, metrics=[my_iou_metric])\n",
        "\n",
        "#model1.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "70ccLHGaIWfA",
        "colab_type": "code",
        "outputId": "3f56ded9-e890-4fee-e8d3-408e533cff59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3468
        }
      },
      "cell_type": "code",
      "source": [
        "#early_stopping = EarlyStopping(monitor='my_iou_metric', mode = 'max',patience=10, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint(save_model_name,monitor='my_iou_metric', \n",
        "                                   mode = 'max', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='my_iou_metric', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "history = model1.fit(x_train, y_train,\n",
        "                    validation_data=[x_valid, y_valid], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[ model_checkpoint,reduce_lr], \n",
        "                    verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            " - 99s - loss: 0.4026 - my_iou_metric: 0.3916 - val_loss: 2.0329 - val_my_iou_metric: 0.3762\n",
            "\n",
            "Epoch 00001: my_iou_metric improved from -inf to 0.39159, saving model to Unet_resnet_v5.model\n",
            "Epoch 2/50\n",
            " - 86s - loss: 0.3167 - my_iou_metric: 0.5282 - val_loss: 0.3636 - val_my_iou_metric: 0.5309\n",
            "\n",
            "Epoch 00002: my_iou_metric improved from 0.39159 to 0.52820, saving model to Unet_resnet_v5.model\n",
            "Epoch 3/50\n",
            " - 86s - loss: 0.2790 - my_iou_metric: 0.5649 - val_loss: 0.2927 - val_my_iou_metric: 0.5432\n",
            "\n",
            "Epoch 00003: my_iou_metric improved from 0.52820 to 0.56489, saving model to Unet_resnet_v5.model\n",
            "Epoch 4/50\n",
            " - 86s - loss: 0.2568 - my_iou_metric: 0.5746 - val_loss: 1.0277 - val_my_iou_metric: 0.0832\n",
            "\n",
            "Epoch 00004: my_iou_metric improved from 0.56489 to 0.57456, saving model to Unet_resnet_v5.model\n",
            "Epoch 5/50\n",
            " - 86s - loss: 0.2616 - my_iou_metric: 0.5737 - val_loss: 0.2732 - val_my_iou_metric: 0.5377\n",
            "\n",
            "Epoch 00005: my_iou_metric did not improve from 0.57456\n",
            "Epoch 6/50\n",
            " - 86s - loss: 0.2308 - my_iou_metric: 0.5879 - val_loss: 0.6366 - val_my_iou_metric: 0.4401\n",
            "\n",
            "Epoch 00006: my_iou_metric improved from 0.57456 to 0.58788, saving model to Unet_resnet_v5.model\n",
            "Epoch 7/50\n",
            " - 86s - loss: 0.2263 - my_iou_metric: 0.5976 - val_loss: 0.2280 - val_my_iou_metric: 0.6115\n",
            "\n",
            "Epoch 00007: my_iou_metric improved from 0.58788 to 0.59761, saving model to Unet_resnet_v5.model\n",
            "Epoch 8/50\n",
            " - 86s - loss: 0.2072 - my_iou_metric: 0.6128 - val_loss: 0.3171 - val_my_iou_metric: 0.5389\n",
            "\n",
            "Epoch 00008: my_iou_metric improved from 0.59761 to 0.61280, saving model to Unet_resnet_v5.model\n",
            "Epoch 9/50\n",
            " - 85s - loss: 0.2015 - my_iou_metric: 0.6197 - val_loss: 0.2314 - val_my_iou_metric: 0.6526\n",
            "\n",
            "Epoch 00009: my_iou_metric improved from 0.61280 to 0.61969, saving model to Unet_resnet_v5.model\n",
            "Epoch 10/50\n",
            " - 86s - loss: 0.1959 - my_iou_metric: 0.6357 - val_loss: 0.1858 - val_my_iou_metric: 0.6664\n",
            "\n",
            "Epoch 00010: my_iou_metric improved from 0.61969 to 0.63570, saving model to Unet_resnet_v5.model\n",
            "Epoch 11/50\n",
            " - 86s - loss: 0.1920 - my_iou_metric: 0.6463 - val_loss: 0.2530 - val_my_iou_metric: 0.5442\n",
            "\n",
            "Epoch 00011: my_iou_metric improved from 0.63570 to 0.64630, saving model to Unet_resnet_v5.model\n",
            "Epoch 12/50\n",
            " - 85s - loss: 0.1808 - my_iou_metric: 0.6506 - val_loss: 0.2009 - val_my_iou_metric: 0.6687\n",
            "\n",
            "Epoch 00012: my_iou_metric improved from 0.64630 to 0.65058, saving model to Unet_resnet_v5.model\n",
            "Epoch 13/50\n",
            " - 86s - loss: 0.1750 - my_iou_metric: 0.6617 - val_loss: 0.1653 - val_my_iou_metric: 0.6975\n",
            "\n",
            "Epoch 00013: my_iou_metric improved from 0.65058 to 0.66166, saving model to Unet_resnet_v5.model\n",
            "Epoch 14/50\n",
            " - 86s - loss: 0.1728 - my_iou_metric: 0.6711 - val_loss: 0.1903 - val_my_iou_metric: 0.6957\n",
            "\n",
            "Epoch 00014: my_iou_metric improved from 0.66166 to 0.67114, saving model to Unet_resnet_v5.model\n",
            "Epoch 15/50\n",
            " - 86s - loss: 0.1653 - my_iou_metric: 0.6837 - val_loss: 0.1779 - val_my_iou_metric: 0.6985\n",
            "\n",
            "Epoch 00015: my_iou_metric improved from 0.67114 to 0.68372, saving model to Unet_resnet_v5.model\n",
            "Epoch 16/50\n",
            " - 85s - loss: 0.1594 - my_iou_metric: 0.6893 - val_loss: 0.3452 - val_my_iou_metric: 0.5409\n",
            "\n",
            "Epoch 00016: my_iou_metric improved from 0.68372 to 0.68930, saving model to Unet_resnet_v5.model\n",
            "Epoch 17/50\n",
            " - 86s - loss: 0.1615 - my_iou_metric: 0.6928 - val_loss: 0.1960 - val_my_iou_metric: 0.6337\n",
            "\n",
            "Epoch 00017: my_iou_metric improved from 0.68930 to 0.69278, saving model to Unet_resnet_v5.model\n",
            "Epoch 18/50\n",
            " - 85s - loss: 0.1537 - my_iou_metric: 0.6960 - val_loss: 0.2018 - val_my_iou_metric: 0.5878\n",
            "\n",
            "Epoch 00018: my_iou_metric improved from 0.69278 to 0.69598, saving model to Unet_resnet_v5.model\n",
            "Epoch 19/50\n",
            " - 85s - loss: 0.1503 - my_iou_metric: 0.7063 - val_loss: 0.1511 - val_my_iou_metric: 0.7245\n",
            "\n",
            "Epoch 00019: my_iou_metric improved from 0.69598 to 0.70627, saving model to Unet_resnet_v5.model\n",
            "Epoch 20/50\n",
            " - 86s - loss: 0.1463 - my_iou_metric: 0.7124 - val_loss: 0.1709 - val_my_iou_metric: 0.6896\n",
            "\n",
            "Epoch 00020: my_iou_metric improved from 0.70627 to 0.71236, saving model to Unet_resnet_v5.model\n",
            "Epoch 21/50\n",
            " - 86s - loss: 0.1427 - my_iou_metric: 0.7196 - val_loss: 0.1563 - val_my_iou_metric: 0.7157\n",
            "\n",
            "Epoch 00021: my_iou_metric improved from 0.71236 to 0.71962, saving model to Unet_resnet_v5.model\n",
            "Epoch 22/50\n",
            " - 86s - loss: 0.1413 - my_iou_metric: 0.7089 - val_loss: 0.2203 - val_my_iou_metric: 0.6091\n",
            "\n",
            "Epoch 00022: my_iou_metric did not improve from 0.71962\n",
            "Epoch 23/50\n",
            " - 85s - loss: 0.1354 - my_iou_metric: 0.7221 - val_loss: 0.1977 - val_my_iou_metric: 0.6633\n",
            "\n",
            "Epoch 00023: my_iou_metric improved from 0.71962 to 0.72206, saving model to Unet_resnet_v5.model\n",
            "Epoch 24/50\n",
            " - 86s - loss: 0.1366 - my_iou_metric: 0.7314 - val_loss: 0.1422 - val_my_iou_metric: 0.7205\n",
            "\n",
            "Epoch 00024: my_iou_metric improved from 0.72206 to 0.73141, saving model to Unet_resnet_v5.model\n",
            "Epoch 25/50\n",
            " - 86s - loss: 0.1366 - my_iou_metric: 0.7228 - val_loss: 0.1516 - val_my_iou_metric: 0.7287\n",
            "\n",
            "Epoch 00025: my_iou_metric did not improve from 0.73141\n",
            "Epoch 26/50\n",
            " - 86s - loss: 0.1351 - my_iou_metric: 0.7293 - val_loss: 0.1570 - val_my_iou_metric: 0.7029\n",
            "\n",
            "Epoch 00026: my_iou_metric did not improve from 0.73141\n",
            "Epoch 27/50\n",
            " - 86s - loss: 0.1298 - my_iou_metric: 0.7350 - val_loss: 0.1218 - val_my_iou_metric: 0.7501\n",
            "\n",
            "Epoch 00027: my_iou_metric improved from 0.73141 to 0.73497, saving model to Unet_resnet_v5.model\n",
            "Epoch 28/50\n",
            " - 86s - loss: 0.1267 - my_iou_metric: 0.7354 - val_loss: 0.1344 - val_my_iou_metric: 0.7497\n",
            "\n",
            "Epoch 00028: my_iou_metric improved from 0.73497 to 0.73542, saving model to Unet_resnet_v5.model\n",
            "Epoch 29/50\n",
            " - 86s - loss: 0.1257 - my_iou_metric: 0.7424 - val_loss: 0.2061 - val_my_iou_metric: 0.7082\n",
            "\n",
            "Epoch 00029: my_iou_metric improved from 0.73542 to 0.74241, saving model to Unet_resnet_v5.model\n",
            "Epoch 30/50\n",
            " - 86s - loss: 0.1226 - my_iou_metric: 0.7344 - val_loss: 0.1341 - val_my_iou_metric: 0.7374\n",
            "\n",
            "Epoch 00030: my_iou_metric did not improve from 0.74241\n",
            "Epoch 31/50\n",
            " - 86s - loss: 0.1232 - my_iou_metric: 0.7374 - val_loss: 0.1431 - val_my_iou_metric: 0.7427\n",
            "\n",
            "Epoch 00031: my_iou_metric did not improve from 0.74241\n",
            "Epoch 32/50\n",
            " - 86s - loss: 0.1225 - my_iou_metric: 0.7408 - val_loss: 0.1371 - val_my_iou_metric: 0.7506\n",
            "\n",
            "Epoch 00032: my_iou_metric did not improve from 0.74241\n",
            "Epoch 33/50\n",
            " - 85s - loss: 0.1212 - my_iou_metric: 0.7416 - val_loss: 0.1621 - val_my_iou_metric: 0.7221\n",
            "\n",
            "Epoch 00033: my_iou_metric did not improve from 0.74241\n",
            "Epoch 34/50\n",
            " - 86s - loss: 0.1248 - my_iou_metric: 0.7400 - val_loss: 0.1230 - val_my_iou_metric: 0.7449\n",
            "\n",
            "Epoch 00034: my_iou_metric did not improve from 0.74241\n",
            "\n",
            "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.\n",
            "Epoch 35/50\n",
            " - 86s - loss: 0.1046 - my_iou_metric: 0.7618 - val_loss: 0.1279 - val_my_iou_metric: 0.7659\n",
            "\n",
            "Epoch 00035: my_iou_metric improved from 0.74241 to 0.76181, saving model to Unet_resnet_v5.model\n",
            "Epoch 36/50\n",
            " - 86s - loss: 0.1024 - my_iou_metric: 0.7642 - val_loss: 0.1263 - val_my_iou_metric: 0.7588\n",
            "\n",
            "Epoch 00036: my_iou_metric improved from 0.76181 to 0.76423, saving model to Unet_resnet_v5.model\n",
            "Epoch 37/50\n",
            " - 86s - loss: 0.1034 - my_iou_metric: 0.7638 - val_loss: 0.1248 - val_my_iou_metric: 0.7655\n",
            "\n",
            "Epoch 00037: my_iou_metric did not improve from 0.76423\n",
            "Epoch 38/50\n",
            " - 86s - loss: 0.0998 - my_iou_metric: 0.7640 - val_loss: 0.1154 - val_my_iou_metric: 0.7714\n",
            "\n",
            "Epoch 00038: my_iou_metric did not improve from 0.76423\n",
            "Epoch 39/50\n",
            " - 86s - loss: 0.1005 - my_iou_metric: 0.7668 - val_loss: 0.1180 - val_my_iou_metric: 0.7710\n",
            "\n",
            "Epoch 00039: my_iou_metric improved from 0.76423 to 0.76677, saving model to Unet_resnet_v5.model\n",
            "Epoch 40/50\n",
            " - 86s - loss: 0.0961 - my_iou_metric: 0.7678 - val_loss: 0.1139 - val_my_iou_metric: 0.7721\n",
            "\n",
            "Epoch 00040: my_iou_metric improved from 0.76677 to 0.76780, saving model to Unet_resnet_v5.model\n",
            "Epoch 41/50\n",
            " - 86s - loss: 0.0946 - my_iou_metric: 0.7720 - val_loss: 0.1203 - val_my_iou_metric: 0.7521\n",
            "\n",
            "Epoch 00041: my_iou_metric improved from 0.76780 to 0.77200, saving model to Unet_resnet_v5.model\n",
            "Epoch 42/50\n",
            " - 86s - loss: 0.0948 - my_iou_metric: 0.7693 - val_loss: 0.1142 - val_my_iou_metric: 0.7621\n",
            "\n",
            "Epoch 00042: my_iou_metric did not improve from 0.77200\n",
            "Epoch 43/50\n",
            " - 86s - loss: 0.0926 - my_iou_metric: 0.7711 - val_loss: 0.1351 - val_my_iou_metric: 0.7426\n",
            "\n",
            "Epoch 00043: my_iou_metric did not improve from 0.77200\n",
            "Epoch 44/50\n",
            " - 86s - loss: 0.0950 - my_iou_metric: 0.7694 - val_loss: 0.1294 - val_my_iou_metric: 0.7540\n",
            "\n",
            "Epoch 00044: my_iou_metric did not improve from 0.77200\n",
            "Epoch 45/50\n",
            " - 86s - loss: 0.0927 - my_iou_metric: 0.7788 - val_loss: 0.1075 - val_my_iou_metric: 0.7779\n",
            "\n",
            "Epoch 00045: my_iou_metric improved from 0.77200 to 0.77878, saving model to Unet_resnet_v5.model\n",
            "Epoch 46/50\n",
            " - 86s - loss: 0.0921 - my_iou_metric: 0.7755 - val_loss: 0.1405 - val_my_iou_metric: 0.7531\n",
            "\n",
            "Epoch 00046: my_iou_metric did not improve from 0.77878\n",
            "Epoch 47/50\n",
            " - 86s - loss: 0.0907 - my_iou_metric: 0.7780 - val_loss: 0.1167 - val_my_iou_metric: 0.7761\n",
            "\n",
            "Epoch 00047: my_iou_metric did not improve from 0.77878\n",
            "Epoch 48/50\n",
            " - 86s - loss: 0.0881 - my_iou_metric: 0.7770 - val_loss: 0.1293 - val_my_iou_metric: 0.7697\n",
            "\n",
            "Epoch 00048: my_iou_metric did not improve from 0.77878\n",
            "Epoch 49/50\n",
            " - 86s - loss: 0.0888 - my_iou_metric: 0.7831 - val_loss: 0.1135 - val_my_iou_metric: 0.7789\n",
            "\n",
            "Epoch 00049: my_iou_metric improved from 0.77878 to 0.78314, saving model to Unet_resnet_v5.model\n",
            "Epoch 50/50\n",
            " - 86s - loss: 0.0884 - my_iou_metric: 0.7826 - val_loss: 0.1401 - val_my_iou_metric: 0.7465\n",
            "\n",
            "Epoch 00050: my_iou_metric did not improve from 0.78314\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F3DZKuF7IjfX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model1 = load_model(save_model_name,custom_objects={'my_iou_metric': my_iou_metric})\n",
        "# remove layter activation layer and use losvasz loss\n",
        "input_x = model1.layers[0].input\n",
        "\n",
        "output_layer = model1.layers[-1].input\n",
        "model = Model(input_x, output_layer)\n",
        "c = optimizers.adam(lr = 0.01)\n",
        "\n",
        "# lovasz_loss need input range (-∞，+∞), so cancel the last \"sigmoid\" activation  \n",
        "# Then the default threshod for pixel prediction is 0 instead of 0.5, as in my_iou_metric_2.\n",
        "model.compile(loss=lovasz_loss, optimizer=c, metrics=[my_iou_metric_2])\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uxub5diSesTD",
        "colab_type": "code",
        "outputId": "be7cd950-d596-4230-826b-01a829996b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_my_iou_metric_2', mode = 'max',patience=20, verbose=1)\n",
        "model_checkpoint = ModelCheckpoint(save_model_name,monitor='val_my_iou_metric_2', \n",
        "                                   mode = 'max', save_best_only=True, verbose=1)\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_my_iou_metric_2', mode = 'max',factor=0.5, patience=5, min_lr=0.0001, verbose=1)\n",
        "epochs = 50\n",
        "batch_size = 32\n",
        "\n",
        "history = model.fit(x_train, y_train,\n",
        "                    validation_data=[x_valid, y_valid], \n",
        "                    epochs=epochs,\n",
        "                    batch_size=batch_size,\n",
        "                    callbacks=[ model_checkpoint,reduce_lr,early_stopping], \n",
        "                    verbose=2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6400 samples, validate on 800 samples\n",
            "Epoch 1/50\n",
            " - 207s - loss: 0.4332 - my_iou_metric_2: 0.7752 - val_loss: 0.7150 - val_my_iou_metric_2: 0.6336\n",
            "\n",
            "Epoch 00001: val_my_iou_metric_2 improved from -inf to 0.63362, saving model to Unet_resnet_v5.model\n",
            "Epoch 2/50\n",
            " - 194s - loss: 0.3900 - my_iou_metric_2: 0.7830 - val_loss: 0.4719 - val_my_iou_metric_2: 0.7439\n",
            "\n",
            "Epoch 00002: val_my_iou_metric_2 improved from 0.63362 to 0.74388, saving model to Unet_resnet_v5.model\n",
            "Epoch 3/50\n",
            " - 194s - loss: 0.3937 - my_iou_metric_2: 0.7784 - val_loss: 0.4903 - val_my_iou_metric_2: 0.7328\n",
            "\n",
            "Epoch 00003: val_my_iou_metric_2 did not improve from 0.74388\n",
            "Epoch 4/50\n",
            " - 193s - loss: 0.3953 - my_iou_metric_2: 0.7762 - val_loss: 0.4096 - val_my_iou_metric_2: 0.7699\n",
            "\n",
            "Epoch 00004: val_my_iou_metric_2 improved from 0.74388 to 0.76987, saving model to Unet_resnet_v5.model\n",
            "Epoch 5/50\n",
            " - 193s - loss: 0.3847 - my_iou_metric_2: 0.7811 - val_loss: 0.4302 - val_my_iou_metric_2: 0.7570\n",
            "\n",
            "Epoch 00005: val_my_iou_metric_2 did not improve from 0.76987\n",
            "Epoch 6/50\n",
            " - 193s - loss: 0.3957 - my_iou_metric_2: 0.7733 - val_loss: 0.4427 - val_my_iou_metric_2: 0.7573\n",
            "\n",
            "Epoch 00006: val_my_iou_metric_2 did not improve from 0.76987\n",
            "Epoch 7/50\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RgAPG7NrexaU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig, (ax_loss, ax_score) = plt.subplots(1, 2, figsize=(15,5))\n",
        "ax_loss.plot(history.epoch, history.history[\"loss\"], label=\"Train loss\")\n",
        "ax_loss.plot(history.epoch, history.history[\"val_loss\"], label=\"Validation loss\")\n",
        "ax_loss.legend()\n",
        "ax_score.plot(history.epoch, history.history[\"my_iou_metric_2\"], label=\"Train score\")\n",
        "ax_score.plot(history.epoch, history.history[\"val_my_iou_metric_2\"], label=\"Validation score\")\n",
        "ax_score.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qG5Cfxcue0Ze",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = load_model(save_model_name,custom_objects={'my_iou_metric_2': my_iou_metric_2,\n",
        "                                                   'lovasz_loss': lovasz_loss})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yNDnekQye3R1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def predict_result(model,x_test,img_size_target): # predict both orginal and reflect x\n",
        "    x_test_reflect =  np.array([np.fliplr(x) for x in x_test])\n",
        "    preds_test = model.predict(x_test).reshape(-1, img_size_target, img_size_target)\n",
        "    preds_test2_refect = model.predict(x_test_reflect).reshape(-1, img_size_target, img_size_target)\n",
        "    preds_test += np.array([ np.fliplr(x) for x in preds_test2_refect] )\n",
        "    return preds_test/2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RNV-L6Bue6B4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "preds_valid = predict_result(model,x_valid,img_size_target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pik_WGwae7uV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Score the model and do a threshold optimization by the best IoU.\n",
        "\n",
        "# src: https://www.kaggle.com/aglotero/another-iou-metric\n",
        "def iou_metric(y_true_in, y_pred_in, print_table=False):\n",
        "    labels = y_true_in\n",
        "    y_pred = y_pred_in\n",
        "\n",
        "\n",
        "    true_objects = 2\n",
        "    pred_objects = 2\n",
        "\n",
        "    #  if all zeros, original code  generate wrong  bins [-0.5 0 0.5],\n",
        "    temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=([0,0.5,1], [0,0.5, 1]))\n",
        "#     temp1 = np.histogram2d(labels.flatten(), y_pred.flatten(), bins=(true_objects, pred_objects))\n",
        "    #print(temp1)\n",
        "    intersection = temp1[0]\n",
        "    #print(\"temp2 = \",temp1[1])\n",
        "    #print(intersection.shape)\n",
        "   # print(intersection)\n",
        "    # Compute areas (needed for finding the union between all objects)\n",
        "    #print(np.histogram(labels, bins = true_objects))\n",
        "    area_true = np.histogram(labels,bins=[0,0.5,1])[0]\n",
        "    #print(\"area_true = \",area_true)\n",
        "    area_pred = np.histogram(y_pred, bins=[0,0.5,1])[0]\n",
        "    area_true = np.expand_dims(area_true, -1)\n",
        "    area_pred = np.expand_dims(area_pred, 0)\n",
        "\n",
        "    # Compute union\n",
        "    union = area_true + area_pred - intersection\n",
        "  \n",
        "    # Exclude background from the analysis\n",
        "    intersection = intersection[1:,1:]\n",
        "    intersection[intersection == 0] = 1e-9\n",
        "    \n",
        "    union = union[1:,1:]\n",
        "    union[union == 0] = 1e-9\n",
        "\n",
        "    # Compute the intersection over union\n",
        "    iou = intersection / union\n",
        "\n",
        "    # Precision helper function\n",
        "    def precision_at(threshold, iou):\n",
        "        matches = iou > threshold\n",
        "        true_positives = np.sum(matches, axis=1) == 1   # Correct objects\n",
        "        false_positives = np.sum(matches, axis=0) == 0  # Missed objects\n",
        "        false_negatives = np.sum(matches, axis=1) == 0  # Extra objects\n",
        "        tp, fp, fn = np.sum(true_positives), np.sum(false_positives), np.sum(false_negatives)\n",
        "        return tp, fp, fn\n",
        "\n",
        "    # Loop over IoU thresholds\n",
        "    prec = []\n",
        "    if print_table:\n",
        "        print(\"Thresh\\tTP\\tFP\\tFN\\tPrec.\")\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        tp, fp, fn = precision_at(t, iou)\n",
        "        if (tp + fp + fn) > 0:\n",
        "            p = tp / (tp + fp + fn)\n",
        "        else:\n",
        "            p = 0\n",
        "        if print_table:\n",
        "            print(\"{:1.3f}\\t{}\\t{}\\t{}\\t{:1.3f}\".format(t, tp, fp, fn, p))\n",
        "        prec.append(p)\n",
        "    \n",
        "    if print_table:\n",
        "        print(\"AP\\t-\\t-\\t-\\t{:1.3f}\".format(np.mean(prec)))\n",
        "    return np.mean(prec)\n",
        "\n",
        "def iou_metric_batch(y_true_in, y_pred_in):\n",
        "    batch_size = y_true_in.shape[0]\n",
        "    metric = []\n",
        "    for batch in range(batch_size):\n",
        "        value = iou_metric(y_true_in[batch], y_pred_in[batch])\n",
        "        metric.append(value)\n",
        "    return np.mean(metric)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LoBXBXlee_OE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Scoring for last model, choose threshold by validation data \n",
        "thresholds_ori = np.linspace(0.3, 0.7, 31)\n",
        "# Reverse sigmoid function: Use code below because the  sigmoid activation was removed\n",
        "thresholds = np.log(thresholds_ori/(1-thresholds_ori)) \n",
        "\n",
        "# ious = np.array([get_iou_vector(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
        "# print(ious)\n",
        "ious = np.array([iou_metric_batch(y_valid, preds_valid > threshold) for threshold in tqdm_notebook(thresholds)])\n",
        "print(ious)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v2WAK60wfBYw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# instead of using default 0 as threshold, use validation data to find the best threshold.\n",
        "threshold_best_index = np.argmax(ious) \n",
        "iou_best = ious[threshold_best_index]\n",
        "threshold_best = thresholds[threshold_best_index]\n",
        "\n",
        "plt.plot(thresholds, ious)\n",
        "plt.plot(threshold_best, iou_best, \"xr\", label=\"Best threshold\")\n",
        "plt.xlabel(\"Threshold\")\n",
        "plt.ylabel(\"IoU\")\n",
        "plt.title(\"Threshold vs IoU ({}, {})\".format(threshold_best, iou_best))\n",
        "plt.legend()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fc3YRSfIfE_Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}