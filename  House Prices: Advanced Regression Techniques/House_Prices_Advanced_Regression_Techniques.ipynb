{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " House Prices: Advanced Regression Techniques.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toandaominh1997/Kaggle/blob/master/%20House%20Prices%3A%20Advanced%20Regression%20Techniques/House_Prices_Advanced_Regression_Techniques.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "CevyAS1PfVxX",
        "colab_type": "code",
        "outputId": "d5736865-14ad-46f9-b837-28df1fec9688",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VYT1CycifZMp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "path_train = 'drive/My Drive/Datasets/House Prices: Advanced Regression Techniques/train.csv'\n",
        "path_test = 'drive/My Drive/Datasets/House Prices: Advanced Regression Techniques/test.csv'\n",
        "train=pd.read_csv(path_train)\n",
        "test=pd.read_csv(path_test)\n",
        "testID = test['Id']\n",
        "target = train['SalePrice']\n",
        "train = train.drop(columns=['SalePrice', 'Id'], axis=1)\n",
        "test = test.drop(columns=['Id'], axis=1)\n",
        "\n",
        "train = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n",
        "\n",
        "\n",
        "\n",
        "all_data = pd.concat([train, test], axis=0)\n",
        "\n",
        "all_data_na = (all_data.isnull().sum() / len(all_data)) * 100\n",
        "all_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\n",
        "all_data[\"PoolQC\"] = all_data[\"PoolQC\"].fillna(\"None\")\n",
        "all_data[\"MiscFeature\"] = all_data[\"MiscFeature\"].fillna(\"None\")\n",
        "all_data[\"Alley\"] = all_data[\"Alley\"].fillna(\"None\")\n",
        "all_data[\"Fence\"] = all_data[\"Fence\"].fillna(\"None\")\n",
        "all_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\n",
        "all_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n",
        "    lambda x: x.fillna(x.median()))\n",
        "for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n",
        "    all_data[col] = all_data[col].fillna('None')\n",
        "    \n",
        "for col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n",
        "    all_data[col] = all_data[col].fillna(0)\n",
        "for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
        "    all_data[col] = all_data[col].fillna(0)\n",
        "all_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\n",
        "all_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\n",
        "all_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])\n",
        "all_data = all_data.drop(['Utilities'], axis=1)\n",
        "all_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\n",
        "all_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\n",
        "all_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\n",
        "all_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\n",
        "all_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\n",
        "all_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\n",
        "all_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n",
        "all_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n",
        "\n",
        "\n",
        "#Changing OverallCond into a categorical variable\n",
        "all_data['OverallCond'] = all_data['OverallCond'].astype(str)\n",
        "\n",
        "\n",
        "#Year and month sold are transformed into categorical features.\n",
        "all_data['YrSold'] = all_data['YrSold'].astype(str)\n",
        "all_data['MoSold'] = all_data['MoSold'].astype(str)\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "cols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n",
        "        'ExterQual', 'ExterCond','HeatingQC', 'PoolQC', 'KitchenQual', 'BsmtFinType1', \n",
        "        'BsmtFinType2', 'Functional', 'Fence', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n",
        "        'LotShape', 'PavedDrive', 'Street', 'Alley', 'CentralAir', 'MSSubClass', 'OverallCond', \n",
        "        'YrSold', 'MoSold')\n",
        "# process columns, apply LabelEncoder to categorical features\n",
        "for c in cols:\n",
        "    lbl = LabelEncoder() \n",
        "    lbl.fit(list(all_data[c].values)) \n",
        "    all_data[c] = lbl.transform(list(all_data[c].values))\n",
        "\n",
        "# shape        \n",
        "print('Shape all_data: {}'.format(all_data.shape))\n",
        "all_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']\n",
        "all_data = pd.get_dummies(all_data)\n",
        "print(all_data.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V3Yp_Yz5gg1O",
        "colab_type": "code",
        "outputId": "3995b381-78f1-400d-b4c9-00a1b764de80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1057
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "\n",
        "def rmse(y_true, y_pred):\n",
        "  return np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "def pd2np(data, dtype=np.float32):\n",
        "  return np.asarray(data, dtype=dtype)\n",
        "\n",
        "train = pd2np(train)\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn import svm\n",
        "from sklearn import linear_model\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "kf = KFold(n_splits=20)\n",
        "clf = SGDRegressor()\n",
        "# clf = Ridge(alpha=.5)\n",
        "# clf = svm.SVR()\n",
        "# clf = linear_model.Lasso(alpha=0.1)\n",
        "# clf = RandomForestRegressor(max_depth=2, random_state=0, n_estimators=100)\n",
        "bestmodel = clf\n",
        "bestscore = 10000000000\n",
        "for train_index, val_index in kf.split(train):\n",
        "  X_train, X_val= train[train_index], train[val_index]\n",
        "  y_train, y_val = target[train_index], target[val_index]\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(\"Score RMSE = \", rmse(y_val, clf.predict(X_val)))\n",
        "  score = rmse(y_val, clf.predict(X_val))\n",
        "  if(bestscore> score):\n",
        "    bestscore = score\n",
        "    bestmodel = clf\n",
        "  \n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score RMSE =  4.676780258332672e+16\n",
            "Score RMSE =  3.6679070813602184e+16\n",
            "Score RMSE =  5.909105595116116e+17\n",
            "Score RMSE =  2.0241403600057296e+17\n",
            "Score RMSE =  4.558935970465732e+17\n",
            "Score RMSE =  1.3749540505367778e+17\n",
            "Score RMSE =  1.078157664861803e+17\n",
            "Score RMSE =  1.061759936897099e+17\n",
            "Score RMSE =  5.272190866220759e+16\n",
            "Score RMSE =  1.0527296335076926e+17\n",
            "Score RMSE =  8.225055493150285e+16\n",
            "Score RMSE =  2.249299268119418e+16\n",
            "Score RMSE =  8.06236256405315e+16\n",
            "Score RMSE =  1.1323650455987347e+17\n",
            "Score RMSE =  5.316624888058047e+16\n",
            "Score RMSE =  1.318947695150932e+17\n",
            "Score RMSE =  1.3854001301173989e+17\n",
            "Score RMSE =  2.0376796514539347e+17\n",
            "Score RMSE =  1.0335417592617016e+17\n",
            "Score RMSE =  1.760975658538119e+17\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
            "  FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "rErH1vxw-6mD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4d05bd72-492f-4d33-c933-dbc16ff3cf0e"
      },
      "cell_type": "code",
      "source": [
        "print(\"Score RMSE = \", rmse(target, bestmodel.predict(train)))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score RMSE =  1.890478567832039e+17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MT8sHKsDCUUb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "28d3992e-8c07-425e-d166-b6fce215f202"
      },
      "cell_type": "code",
      "source": [
        "test.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "metadata": {
        "id": "plX--xFvgeOB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "submit = pd.DataFrame()\n",
        "submit['Id'] = test['Id']\n",
        "submit['SalePrice'] = bestmodel.predict(test)\n",
        "submit.to_csv('submit.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VAqAh9wouDFm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}